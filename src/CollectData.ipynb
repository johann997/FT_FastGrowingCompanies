{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# from geopy.exc import GeocoderTimedOut\n",
    "# from geopy.geocoders import Nominatim\n",
    "\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 70)\n",
    "\n",
    "# import plotly.offline as pyo\n",
    "# pyo.init_notebook_mode(connected=True)\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = \"vscode\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_url(url):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the table in the page (you might need to adjust the class or ID if the table is dynamic)\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    # Extract the headers\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "\n",
    "    # Extract the rows\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        rows.append(cells)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019', '2020', '2021', '2022', '2023', '2024']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL\n",
    "base_url = \"https://www.ft.com/ft1000-\"\n",
    "years = [str(num) for num in range(2019, 2025)]\n",
    "\n",
    "years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['Rank', 'Company', 'In 2018 list?', 'In 2017 list?', 'Country', 'Sector', 'Absolute revenue growth', 'Revenue CAGR 2014-17', 'Revenue 2017 (€m)', 'Employee growth 2014-17', 'Employees 2017', 'Founded']\n",
      "Column names: ['Rank', 'Name', 'in 2019 ranking', 'in 2018 ranking', 'Country', 'FT Category', 'Absolute Growth Rate [in %]', 'Compound Annual   Growth Rate (CAGR) [in %]', 'Revenue 2018 [in €m]', 'Revenue 2015 [in €m]', 'Number of   employees 2018', 'Founding Year']\n",
      "Column names: ['Rank', 'Name', 'in 2020 ranking', 'in 2019 ranking', 'Country', 'FT Category', 'Absolute Growth Rate %', 'Compound Annual Growth Rate (CAGR) %', 'Revenue 2019 €', 'Revenue 2016 €', 'Number of employees 2019', 'Number of employees 2016', 'Founding Year']\n",
      "Column names: ['Rank', 'Name', 'in 2021 ranking', 'in 2020 ranking', 'Country', 'Sector', 'Absolute Growth Rate %', 'Compound Annual Growth Rate (CAGR) %', 'Revenue 2020 (€)', 'Revenue 2017 (€)', 'Number of employees 2020', 'Number of employees 2017', 'Founding Year']\n",
      "Column names: ['Rank', 'Name', 'in 2022 ranking', 'in 2021 ranking', 'Country', 'Sector', 'Absolute Growth Rate %', 'Compound Annual Growth Rate (CAGR) %', 'Revenue 2021 (€)', 'Revenue 2018 (€)', 'Number of employees 2021', 'Number of employees 2018', 'Founding Year']\n",
      "Column names: ['Rank', 'Name', 'Country', 'Sector', 'Absolute Growth Rate (%)', 'Compound Annual Growth Rate (%)', 'Revenue 2022 (€)', 'Revenue 2019 (€)', 'Number of employees 2022', 'Number of employees 2019', 'Founding Year']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_names = []\n",
    "df_list = []\n",
    "\n",
    "for year in years:\n",
    "    url = base_url + year\n",
    "\n",
    "    df = get_df_from_url(url)\n",
    "\n",
    "\n",
    "    column_name = df.columns.tolist()\n",
    "    print(\"Column names:\", column_name)\n",
    "\n",
    "\n",
    "    column_names.append(column_name)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rank', 'Name', 'Country', 'Sector', 'Absolute Growth Rate', 'Compound Annual Growth Rate', 'Revenue 2017', 'Employees 2017', 'Founded', 'Revenue 2018', 'Revenue 2015', 'Employees 2018', 'Revenue 2019', 'Revenue 2016', 'Employees 2019', 'Employees 2016', 'Revenue 2020', 'Employees 2020', 'Revenue 2021', 'Employees 2021', 'Revenue 2022', 'Employees 2022']\n"
     ]
    }
   ],
   "source": [
    "cols_to_delete = [\n",
    "    'In 2018 list?', \n",
    "    'In 2017 list?',\n",
    "    'in 2019 ranking',\n",
    "    'in 2018 ranking',\n",
    "    'in 2020 ranking',\n",
    "    'in 2021 ranking',\n",
    "    'in 2022 ranking',\n",
    "    'Employee growth 2014-17',\n",
    "]\n",
    "\n",
    "company_names = []\n",
    "df_list_copy = []\n",
    "\n",
    "\n",
    "\n",
    "def rename_columns(df, col_names, new_name):\n",
    "    check = 0\n",
    "    for col in col_names:\n",
    "        if check == 1:\n",
    "            break\n",
    "        if col in df.columns:\n",
    "            df.rename(columns={col: new_name}, inplace=True)\n",
    "            check = 1\n",
    "    return df\n",
    "\n",
    "def clean_dataframe_column_names(df):\n",
    "    \"\"\"\n",
    "    Cleans the column names of a DataFrame by:\n",
    "    - Stripping extra spaces (ensuring a single space between words).\n",
    "    - Capitalizing the first word of each column name.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame whose column names need cleaning.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with cleaned column names.\n",
    "    \"\"\"\n",
    "    # Clean each column name\n",
    "    cleaned_columns = [\" \".join(col.split()).title() for col in df.columns]\n",
    "    # Rename columns in the DataFrame\n",
    "    df.columns = cleaned_columns\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "for df_index, df_val in enumerate(df_list):\n",
    "\n",
    "    df = df_val.copy(deep=True)\n",
    "\n",
    "\n",
    "    # print('-'*80)\n",
    "    # print(df.columns)\n",
    "    ##################################################\n",
    "    # rename comapny name\n",
    "    ##################################################\n",
    "    col_names = [\n",
    "        'Company',\n",
    "        ]\n",
    "    df = rename_columns(df, col_names, 'Name')\n",
    "\n",
    "\n",
    "    ##################################################\n",
    "    # rename revenue growth\n",
    "    ##################################################\n",
    "    col_names = [\n",
    "        'Absolute Growth Rate [in %]',\n",
    "        'Absolute Growth Rate %',\n",
    "        'Absolute Growth Rate (%)',\n",
    "        'Absolute revenue growth',\n",
    "        ]\n",
    "    df = rename_columns(df, col_names, 'Absolute Growth Rate')\n",
    "\n",
    "\n",
    "    ##################################################\n",
    "    # rename Compound Annual Growth Rate\n",
    "    ##################################################\n",
    "    col_names = [\n",
    "        'Compound Annual Growth Rate (CAGR) %',\n",
    "        'Compound Annual Growth Rate (%)',\n",
    "        'Revenue CAGR 2014-17',\n",
    "        'Compound Annual   Growth Rate (CAGR) [in %]'\n",
    "        'CAGR'\n",
    "        ]\n",
    "    df = rename_columns(df, col_names, 'Compound Annual Growth Rate')\n",
    "\n",
    "\n",
    "    ##################################################\n",
    "    # rename sector\n",
    "    ##################################################\n",
    "    col_names = [\n",
    "        'Sector',\n",
    "        'FT Category',\n",
    "        ]\n",
    "    df = rename_columns(df, col_names, 'Sector')\n",
    "\n",
    "\n",
    "    ##################################################\n",
    "    # rename founding year\n",
    "    ##################################################\n",
    "    col_names = [\n",
    "        'Founding Year',\n",
    "        'Founded',\n",
    "        ]\n",
    "    df = rename_columns(df, col_names, 'Founded')\n",
    "\n",
    "\n",
    "\n",
    "    ##################################################\n",
    "    # Rename columns containing 'employees'\n",
    "    ##################################################\n",
    "    df.columns = [\n",
    "        re.sub(r'(?:[ ]*[Nn]umber[ ]+of[ ]+)?[Ee]mployees[ ]+(\\d{4})', r'Employees \\1', col, flags=re.IGNORECASE) \n",
    "        if 'employees' in col.lower() else col\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    ##################################################\n",
    "    # Rename columns containing 'revenue'\n",
    "    ##################################################\n",
    "    df.columns = [\n",
    "        re.sub(r'[\\[\\(].*?[\\]\\)]|€|[€]', '', col).strip()  # Clean and preserve spaces\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    # print(df.columns)\n",
    "    \n",
    "    # print(df.columns)\n",
    "    df_list_copy.append(df)\n",
    "    # print(df_list_copy[df_index].columns)\n",
    "    # print('-'*80)\n",
    "\n",
    "\n",
    "\n",
    "unique_col_names = []\n",
    "\n",
    "\n",
    "for df_index, df_val in enumerate(df_list_copy):\n",
    "\n",
    "    df = df_val.copy()\n",
    "\n",
    "    ##################################################\n",
    "    # Delete columns\n",
    "    ##################################################\n",
    "    df = df.drop(columns=[col for col in cols_to_delete if col in df.columns])\n",
    "\n",
    "    df = clean_dataframe_column_names(df)\n",
    "\n",
    "    # print(df.columns)\n",
    "    df_list_copy[df_index] = df\n",
    "\n",
    "    for name in df.columns:\n",
    "        if name not in unique_col_names:\n",
    "            unique_col_names.append(name)\n",
    "\n",
    "print(unique_col_names)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df_list = []\n",
    "\n",
    "for df_index, df_val in enumerate(df_list_copy):\n",
    "    df = df_val.copy()\n",
    "    for col in unique_col_names:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    \n",
    "    df['Year'] = years[df_index]\n",
    "\n",
    "    mega_df_list.append(df)\n",
    "\n",
    "\n",
    "\n",
    "master_df = pd.concat(mega_df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['Sector'] = master_df['Sector'].apply(lambda x: \" \".join(str(x).split()).title() if pd.notna(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mapping = {\n",
    "    'Aerospace & Defence':'Defence',\n",
    "    'Advertising & Marketing': 'Sales & Marketing',\n",
    "    'Advertising': 'Sales & Marketing',\n",
    "    'Sales & Marketing': 'Sales & Marketing',\n",
    "    'Sales And Marketing': 'Sales & Marketing',\n",
    "    'Automobiles': 'Automotive', \n",
    "    'Agricultural Commodities': 'Agricultural',\n",
    "    'Agriculture, Forestry & Fishing': 'Agricultural',\n",
    "    'Apparel & Fashion': 'Fashion',\n",
    "    'Chemicals & Pharmaceuticals': 'Chemicals',\n",
    "    'Construction & Engineering': 'Construction',\n",
    "    'Education & Social Services': 'Education',\n",
    "    'Energy & Utilities': 'Energy',\n",
    "    'Food & Beverages': 'Food & Beverage',\n",
    "    'Fintech, Financial Services & Insurance': 'Financial Services',\n",
    "    'Fintech': 'Financial Services',\n",
    "    'Healh': 'Health',\n",
    "    'Health Care & Life Sciences': 'Health',\n",
    "    'Law': 'Legal', \n",
    "    'Legal & Accounting Services': 'Legal',\n",
    "    'Media & Telecommunications': 'Media',\n",
    "    'Telecoms': 'Media',\n",
    "    'Pharmaceuticals & Cosmetics':'Pharmaceuticals',\n",
    "    'Precious Metals':'Mining',\n",
    "    'Property':'Real Estate',\n",
    "    'Restaurants':'Hospitality',\n",
    "    'Hospitality & Travel':'Hospitality',\n",
    "    'Logistics & Transportation':'Transport',\n",
    "    'Waste Management & Recycling':'Waste Management'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for row_index, row_val in enumerate( master_df['Sector']):\n",
    "    if row_val in sector_mapping:\n",
    "        master_df.iloc[[row_index, master_df.columns.get_loc('Sector')]] = sector_mapping[row_val]\n",
    "        continue\n",
    "\n",
    "# normalized_sectors = [sector_mapping.get(sector, sector) for sector in master_df['Sector'].unique().astype(str)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define the file path for saving the CSV\n",
    "file_path = os.path.join(current_directory, 'data.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "master_df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Technology',\n",
       " 'Construction',\n",
       " 'Ecommerce',\n",
       " 'It & Software',\n",
       " 'Financial Services',\n",
       " 'Sales & Marketing',\n",
       " 'Support Services',\n",
       " 'Retail',\n",
       " 'Energy',\n",
       " 'Management Consulting',\n",
       " 'Industrial Goods',\n",
       " 'Transport',\n",
       " 'Food & Beverage',\n",
       " 'Media',\n",
       " 'Automotive',\n",
       " 'Health',\n",
       " 'Real Estate',\n",
       " 'Wholesale',\n",
       " 'Travel & Leisure',\n",
       " 'Education']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 10 most frequent names\n",
    "n = 20\n",
    "frequenct_sector = master_df['Sector'].value_counts()[:n].index.tolist()\n",
    "\n",
    "frequenct_sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to load info from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/web-scraped-result.csv',\n",
    "#                 delimiter=',',            # Comma as delimiter\n",
    "#                  quotechar='\"',            # Use double quotes for quoting\n",
    "#                 quoting=csv.QUOTE_MINIMAL,  # Minimal quoting (or csv.QUOTE_ALL as needed)\n",
    "#                 doublequote=True, \n",
    "#                 encoding='utf-8',\n",
    "#                 )\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berlin_wall_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
